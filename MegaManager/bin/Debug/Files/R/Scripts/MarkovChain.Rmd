---
title: "Predict OEIS Sequences with Markov Chains"
author: "Enrique Pérez Herrero"
date: "July 20, 2016"
output: html_document
---

## 0 Summary

The `R` script tests the accuracy of a `Markov Chain` based prediction model, 
applied to kaggle's [OEIS](https://oeis.org/) _Integer Sequence Learning 
Competition_, and proposes a characterization of sequences with high prediction 
success, based in the sequence number of terms.


## 1 Introduction

OEIS Sequences are of different types and came from distinct fields: 
combinatorics, number theory (arithmetical functions, prime counting, special 
numbers, continued fractions), calculus,  puzzles, matrices, polynomials,
triangles, equations, base dependant, physics, chemistry...

A random lookup throught the OEIS can show that there are some periodic
sequences, other entries include patterns (that are somehow repeated), and there
are numbers found in most of the sequences for example the numbers from 0 to 9.

This observations invites to consider to use *Markov chains* to predict the next
term in the sequence, as a better alternate to mode prediction, althought this
method is useless to predict stricly increasing (or decreasing) sequences.

An _integer sequence_ can be modelized as a *Markov chain* if it is considered
to be a sequence of random terms $a_1$, $a_2$, $a_3$, ..., $a_n$ with the
_Markov property_, that the probability of the next term depends only on a given
subset of the preceding terms (or state) and not on other previous subsets of
terms.

### 1.1 Loading packages

```{r , message = FALSE}
library(ggplot2)
library(markovchain)
library(data.table)
library(stringr)
```


### 1.2 Reading training data and converting to `data.table`

```{r}
training <- read.csv("C:\\mega.csv", stringsAsFactors = FALSE)
training <- as.data.table(training)
```


### 1.3 Sampling training data

The number of rows in the full training data set is `r training[, .N]`, but
only a subset is used in the test.

```{r}
set.seed(pi)
sample_size <- 6
training <- training[sample(.N, sample_size)]
```


### 1.4 Splitting `Sequence` in `Last` and `Problem`

```{r}
training[, Last := str_extract(Sequence, "\\-?\\d*$")]
training[, Problem := gsub("\\,\\-?\\d*$", "\\1", Sequence)]
```


## 2 Markov Chain prediction model

```{r}
markov_predict <- function(my_problem, n = 3L, verbose = FALSE) {
  my_problem <- unlist(str_split(my_problem, ","))
  len <- length(my_problem)
  n <- min(len, n) # new data length
  new_data <- my_problem[(len - n):len]
  mk <- markovchainFit(my_problem)
  prediction <- predict(object = mk$estimate,
                        newdata = new_data,
                        n.ahead = 1L)
  loglike <- mk$logLikelihood
  answer <-
    list("Markov_Prediction" = prediction,
         "Markov_Loglikelihood" = loglike)
  if(verbose) {
    cat(paste("Markov Prediction:", prediction, "\n"))
    cat(paste("Markov Loglikelihood:", loglike, "\n"))
  }
  return(answer)
}
```


### 2.1 Markov Chain prediction results

```{r}
  markov_result <- t(sapply(training[, Problem], markov_predict))
  training <- cbind(training, markov_result)
  rm(markov_result)
  training[, Markov_Prediction := unlist(Markov_Prediction)]
  training[, Markov_Loglikelihood := unlist(Markov_Loglikelihood)]
  training[, Markov_Success := (Last == Markov_Prediction)]
```


### 2.2 Markov chain prediction accuracy

```{r}
markov_accuracy <-
  (100 * training[Markov_Prediction == Last, .N]) / training[, .N]
cat("Markov Accuracy:", round(markov_accuracy , 4), "%\n")
```


### 2.3 Adding new features

```{r}
training[, Terms := sapply(Problem, function(x)
  length(unlist(str_split(x, ","))))]
training[, Nchar := nchar(Problem)]
training[, Nchar_Digits := (Nchar - (Terms - 1L))]
training[, Avrg_Digits := Nchar_Digits / Terms]
```

Where:

* `Nchar`:  Number of characters in the problem sequence, including commas.
* `Nchar_Digits`: Number of characters in the problem sequence excluding commas.
* `Avrg_Digits`: Average number of digits by term in the sequence (minus sign are
included in the counting).

## 3 Characterizing sequences with high prediction success 

```{r}
max_terms <- max(training[, Terms])
dt_false <-
  density(training[Markov_Success == FALSE, Terms], from = 0, to = max_terms)
dt_true <-
  density(training[Markov_Success == TRUE, Terms], from = 0, to = max_terms)

density_point_x <- dt_true$x[dt_false$y < dt_true$y][[1]]
density_point_x <- round(density_point_x)
density_point_y <- dt_true$y[dt_false$y < dt_true$y][[1]]

ggplot(training, aes(x = Terms, colour = Markov_Success)) +
  geom_density(aes(group = Markov_Success)) +
  geom_point(aes(x = density_point_x, y = density_point_y), colour = "grey50")
```


It is remarkable the distinct distribution of successful predictions, from
unsuccessful ones, as a function of the number of terms in the sequence.

### 3.1 Prediction accuracy of sequences with a high number of terms

```{r}
markov_accuracy_high_terms <-
  (100 * training[(Markov_Success == TRUE) & (Terms > density_point_x), .N]) /
  training[(Terms > density_point_x), .N]
cat("Markov Accuracy of sequences with more than", density_point_x,
    "terms:", round(markov_accuracy_high_terms , 4), "%\n")
```


### 3.2 Percentage of sequences with high number of terms

```{r}
high_terms_sequences <- (100 * training[(Terms > density_point_x), .N]) / 
  training[, .N]
cat("Sequences with more than", density_point_x,
    "terms:", round(high_terms_sequences , 4), "%\n")
```


### 3.3 Density plot: (terms,  number of characters in all terms)

```{r}
ggplot(training, aes(x = Terms, y = Nchar_Digits, colour = Markov_Success)) +
  geom_point(aes(group = Markov_Success), size = .2, alpha = .2) +
  geom_density2d(aes(group = Markov_Success), size = .5)
```


## 4 To Do 

* Test _Ngram_ prediction model based on `quanteda` package.
* Use Markov chains to predict sign, {-1,0,1}
* Use Markov chains to predict some particular modulus of last term, for
instance mod 10, mod 2 or mod 3, and use this modulus prediction to correct
other model predictions, for instance _Newton interpolation_, _linear models_
, etc.

## 5 Links

* [Wikipedia Markov Chain](https://en.wikipedia.org/wiki/Markov_chain)
* [Markov Chains Explained Visually](http://setosa.io/ev/markov-chains/)
* [The markovchain Package: A Package for Easily Handling Discrete Markov Chains
in
R](https://cran.r-project.org/web/packages/markovchain/vignettes/an_introduction_to_markovchain_package.pdf)
* [Package ‘markovchain’](https://cran.r-project.org/web/packages/markovchain/markovchain.pdf)
* [data.table Cheat Sheet](https://s3.amazonaws.com/assets.datacamp.com/img/blog/data+table+cheat+sheet.pdf)
* [My Contributions to OEIS](https://oeis.org/search?q=Enrique+P%C3%A9rez&language=english&go=Search)
* [My Blog](http://psychedelic-geometry.blogspot.com.es/)